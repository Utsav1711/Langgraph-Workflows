{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bbf3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import AnyMessage, AIMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt, Command\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e695eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"openai/gpt-oss-120b\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39b6a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParentState(TypedDict):\n",
    "\n",
    "    question: str\n",
    "    ans_eng: str\n",
    "    ans_hin: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d06037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(state: ParentState):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Translate the following text to Hindi.\n",
    "Keep it natural and clear. Do not add extra content.\n",
    "\n",
    "Text:\n",
    "{state[\"ans_eng\"]}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    translated_text = llm.invoke(prompt).content\n",
    "\n",
    "    return {'ans_hin': translated_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4397055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graph = StateGraph(ParentState)\n",
    "\n",
    "sub_graph.add_node('translate_text', translate_text)\n",
    "\n",
    "sub_graph.add_edge(START, 'translate_text')\n",
    "sub_graph.add_edge('translate_text', END)\n",
    "\n",
    "subgraph = sub_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da809e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: ParentState):\n",
    "\n",
    "    answer = llm.invoke(f\"You are a helpful assistant. Answer clearly.\\n\\nQuestion: {state['question']}\").content\n",
    "    return {'ans_eng': answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24153f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ParentState)\n",
    "\n",
    "graph.add_node(\"answer\", generate_answer)\n",
    "graph.add_node(\"translate\", subgraph)\n",
    "\n",
    "graph.add_edge(START, 'answer')\n",
    "graph.add_edge('answer', 'translate')\n",
    "graph.add_edge('translate', END)\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c663ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001B411CF8DA0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce5728e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is LangGraph?',\n",
       " 'ans_eng': '**LangGraph** is an open‑source Python library (part of the LangChain ecosystem) that makes it easy to build **state‑ful, graph‑structured applications powered by large language models (LLMs)**.  \\n\\n---\\n\\n## Core Idea\\nInstead of writing a linear chain of prompts, you describe a **directed graph** where each node is a *step* (a prompt, a tool call, a conditional branch, etc.) and edges define how control flows from one step to the next based on the **state** that is carried along the execution.\\n\\n| Concept | What it is | Why it matters |\\n|---------|------------|----------------|\\n| **Node** | A callable unit (prompt template, tool, function, sub‑graph, etc.) | Encapsulates a single piece of logic. |\\n| **Edge** | A transition rule that decides the next node | Enables branching, loops, retries, and dynamic routing. |\\n| **State** | A mutable dictionary (or any serialisable object) that persists across nodes | Allows you to keep context, track variables, and make decisions. |\\n| **Graph** | The whole collection of nodes + edges + a runtime engine | Represents the full workflow of a multi‑step LLM application. |\\n\\n---\\n\\n## What Problems Does LangGraph Solve?\\n\\n| Problem | Traditional approach | LangGraph solution |\\n|---------|----------------------|--------------------|\\n| **Complex multi‑step reasoning** (e.g., “plan → retrieve → generate → verify”) | You have to manually stitch together prompts, callbacks, and context management. | Define each step as a node; the engine wires them together automatically. |\\n| **Conditional branching** (e.g., “if user wants a summary, go to summarizer; else go to Q&A”) | You need `if/else` logic scattered throughout your code. | Edges can be conditional functions that read the state and pick the next node. |\\n| **Loops & retries** (e.g., “keep asking the model until answer is valid”) | You write explicit `while` loops and manage termination yourself. | Graph can contain cycles; the runtime handles iteration limits and back‑off strategies. |\\n| **Tool integration** (search APIs, calculators, databases) | You embed tool calls inside prompts or callbacks, often with boilerplate. | Nodes can be *tool* nodes that call any Python function or external API, with automatic input/output handling. |\\n| **Reusability & composability** | Code is monolithic; re‑using a sub‑workflow is painful. | Sub‑graphs can be nested, exported, and reused like functions. |\\n| **Observability & debugging** | Hard to trace which prompt produced which output. | The runtime logs state transitions, node inputs/outputs, and edge decisions, making the flow easy to inspect. |\\n\\n---\\n\\n## Key Components (high‑level)\\n\\n1. **`State`** – a mutable dict (or Pydantic model) that travels with the execution.\\n2. **`Node`** – any callable that receives the current state and returns an updated state (or a partial result). Common node types:\\n   - `LLMNode` – runs a LangChain prompt with an LLM.\\n   - `ToolNode` – calls a Python function or external service.\\n   - `ConditionNode` – evaluates a predicate and decides which edge to follow.\\n   - `SubGraphNode` – invokes another LangGraph graph.\\n3. **`Edge`** – a function (or simple mapping) that, given the state, returns the **key** of the next node.\\n4. **`Graph`** – a collection of nodes + edges + a *start* node.\\n5. **`Executor`** – the runtime that steps through the graph, updates the state, respects loops, and respects termination criteria.\\n\\n---\\n\\n## Minimal Example\\n\\n```python\\nfrom langgraph.graph import Graph\\nfrom langgraph.nodes import LLMNode, ToolNode, ConditionNode\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.llms import OpenAI\\nimport math\\n\\n# 1️⃣ Define nodes\\nprompt = PromptTemplate.from_template(\\n    \"You are a math tutor. Solve: {question}\"\\n)\\nllm_node = LLMNode(OpenAI(), prompt, name=\"solve\")\\n\\ndef is_correct(state):\\n    # Very naive check – in real life you\\'d parse the answer or call a verifier tool\\n    return \"error\" not in state[\"answer\"].lower()\\n\\ncond_node = ConditionNode(is_correct, name=\"check\")\\n\\ndef calculator(state):\\n    # Simple tool that evaluates arithmetic expressions\\n    expr = state[\"question\"]\\n    state[\"answer\"] = str(eval(expr))\\n    return state\\n\\ntool_node = ToolNode(calculator, name=\"calc\")\\n\\n# 2️⃣ Build the graph\\ngraph = Graph(start_node=\"solve\")\\ngraph.add_node(llm_node)\\ngraph.add_node(tool_node)\\ngraph.add_node(cond_node)\\n\\n# Edges\\ngraph.add_edge(\"solve\", \"check\")          # after LLM, go to condition\\ngraph.add_edge(\"check\", \"calc\", condition=True)   # if not correct → calculator\\ngraph.add_edge(\"check\", \"end\", condition=False)  # if correct → finish\\n\\n# 3️⃣ Execute\\ninitial_state = {\"question\": \"12 * 7\"}\\nfinal_state = graph.run(initial_state)\\n\\nprint(final_state[\"answer\"])   # -> \"84\"\\n```\\n\\n*What happens?*  \\n\\n1. **`solve`** runs the LLM prompt.  \\n2. **`check`** inspects the LLM answer.  \\n3. If the answer looks wrong, the edge leads to **`calc`**, which computes the result directly.  \\n4. The graph terminates (`end`) once a satisfactory answer is in the state.\\n\\n---\\n\\n## Typical Use‑Cases\\n\\n| Domain | Example Workflow (graph) |\\n|--------|--------------------------|\\n| **Customer support** | `IntentClassifier → KnowledgeBaseLookup → ResponseGenerator → FeedbackLoop` |\\n| **Research assistant** | `Plan → LiteratureSearch → Summarize → Synthesize → CiteSources` |\\n| **Data analysis** | `ParseUserQuery → ChooseTool (SQL / Pandas / Plot) → ExecuteTool → VerifyResult → Return` |\\n| **Multi‑agent collaboration** | `Coordinator → AgentA (planning) → AgentB (execution) → AgentC (validation) → Merge` |\\n| **Game AI / Narrative** | `SceneGenerator → PlayerChoice → Branch → MemoryUpdate → NextScene` |\\n\\n---\\n\\n## How to Get Started\\n\\n```bash\\npip install langgraph\\n```\\n\\n1. **Read the docs** – the official site (https://langgraph.dev) has a *Getting Started* tutorial and a reference for `Graph`, `Node`, and `Edge`.\\n2. **Pick a base** – you can start from a plain `Graph` or use the higher‑level `StateGraph` helper that automatically creates a `state` object for you.\\n3. **Leverage existing nodes** – LangGraph ships with ready‑made LLM nodes, tool wrappers, and condition nodes, all compatible with LangChain prompt templates and agents.\\n4. **Iterate** – add new nodes, test with `graph.run(state)`, and inspect the execution log (`graph.visualize()` can output a Mermaid diagram).\\n\\n---\\n\\n## Visualisation\\n\\nLangGraph can export the graph to **Mermaid** or **GraphViz**:\\n\\n```python\\nprint(graph.to_mermaid())\\n# or\\ngraph.visualize(output_path=\"my_workflow.png\")\\n```\\n\\nThis makes it easy to share the workflow with non‑technical stakeholders.\\n\\n---\\n\\n## Comparison with Related Projects\\n\\n| Project | Primary Focus | Graph Support | State Management | Tool Integration |\\n|---------|---------------|---------------|------------------|------------------|\\n| **LangChain** | Chains of prompts & agents | Linear/looped chains, no explicit graph syntax | Implicit via `Chain` objects | Built‑in tool wrappers |\\n| **AutoGPT** | Autonomous agents with self‑prompting | Implicit “task graph” via self‑reflection | Global memory store | Plugins for tools |\\n| **LlamaIndex** | Data‑centric retrieval‑augmented generation | Mostly retrieval pipelines | Index‑driven state | Connectors for data sources |\\n| **LangGraph** | Explicit **directed graph** of nodes + **mutable state** | Full DAG/DAG‑with‑cycles support | First‑class `state` dict | Node‑level tool calls, sub‑graphs |\\n\\nLangGraph can be *combined* with LangChain (LLM nodes are just LangChain chains under the hood) and with LlamaIndex (retrieval nodes can be added as tools).\\n\\n---\\n\\n## TL;DR Summary\\n\\n- **LangGraph** = a Python library for **building, executing, and visualizing stateful graph‑based LLM workflows**.\\n- You define **nodes** (LLM calls, tool calls, conditions, sub‑graphs) and **edges** (routing logic) that operate on a shared **state**.\\n- It handles **branching, loops, retries, and composability** out of the box, making complex multi‑step LLM applications easier to write, debug, and maintain.\\n- It sits on top of LangChain, so you can reuse all existing prompt templates, LLM wrappers, and tool integrations.\\n\\nIf you need a structured, maintainable way to orchestrate several LLM calls, tool invocations, and decision points—especially when the flow isn’t a simple linear chain—LangGraph is the go‑to solution.',\n",
       " 'ans_hin': '**LangGraph** एक ओपन‑सॉर्स पायथन लाइब्रेरी (LangChain इकोसिस्टम का हिस्सा) है जो बड़े भाषा मॉडलों (LLMs) द्वारा संचालित **स्थिति‑सचेत, ग्राफ‑संरचित अनुप्रयोग** बनाना आसान बनाती है।  \\n\\n---  \\n\\n## मुख्य विचार  \\nलिनियर प्रॉम्प्ट चेन लिखने के बजाय, आप **एक निर्देशित ग्राफ** वर्णित करते हैं जहाँ प्रत्येक नोड एक *स्टेप* (प्रॉम्प्ट, टूल कॉल, कंडीशनल ब्रांच आदि) होता है और एजेज यह निर्धारित करते हैं कि निष्पादन के दौरान ले जाए जाने वाला अगला नोड कौन‑सा होगा, जो **स्थिति** (state) पर निर्भर करता है।  \\n\\n| अवधारणा | यह क्या है | क्यों महत्वपूर्ण है |\\n|---------|------------|-------------------|\\n| **Node** | एक कॉल करने योग्य इकाई (प्रॉम्प्ट टेम्पलेट, टूल, फ़ंक्शन, सब‑ग्राफ, आदि) | एकल लॉजिक टुकड़े को संलग्न करता है। |\\n| **Edge** | एक ट्रांज़िशन नियम जो अगले नोड का निर्णय लेता है | ब्रांचिंग, लूप, रीट्राई और डायनामिक रूटिंग को सक्षम बनाता है। |\\n| **State** | एक परिवर्तनीय डिक्शनरी (या कोई भी सीरियलाइज़ेबल ऑब्जेक्ट) जो नोड्स के बीच बनी रहती है | संदर्भ बनाए रखने, वेरिएबल ट्रैक करने और निर्णय लेने में मदद करता है। |\\n| **Graph** | नोड्स + एजेज + एक रनटाइम इंजन का पूरा संग्रह | मल्टी‑स्टेप LLM एप्लिकेशन का पूर्ण वर्कफ़्लो दर्शाता है। |\\n\\n---  \\n\\n## LangGraph किन समस्याओं को हल करता है?  \\n\\n| समस्या | पारंपरिक तरीका | LangGraph समाधान |\\n|---------|----------------------|-------------------|\\n| **जटिल मल्टी‑स्टेप रीजनिंग** (उदा. “योजना → रिट्रीव → जेनरेट → वेरिफ़ाई”) | प्रॉम्प्ट, कॉलबैक और कंटेक्स्ट मैनेजमेंट को मैन्युअली जोड़ना पड़ता है। | प्रत्येक स्टेप को नोड के रूप में परिभाषित करें; इंजन उन्हें स्वचालित रूप से जोड़ देता है। |\\n| **कंडीशनल ब्रांचिंग** (उदा. “यदि उपयोगकर्ता सारांश चाहता है तो summarizer पर जाएँ; अन्यथा Q&A पर”) | कोड में `if/else` लॉजिक बिखरा रहता है। | एजेज कंडीशनल फ़ंक्शन हो सकते हैं जो स्थिति पढ़कर अगला नोड चुनते हैं। |\\n| **लूप और रीट्राई** (उदा. “मॉडल से तब तक पूछें जब तक उत्तर वैध न हो”) | स्पष्ट `while` लूप लिखना और टर्मिनेशन खुद संभालना पड़ता है। | ग्राफ में साइकिल हो सकते हैं; रनटाइम इटरेशन लिमिट और बैक‑ऑफ़ रणनीति संभालता है। |\\n| **टूल इंटीग्रेशन** (सर्च API, कैलकुलेटर, डेटाबेस) | टूल कॉल को प्रॉम्प्ट या कॉलबैक में एम्बेड करना, अक्सर बायलरप्लेट के साथ। | नोड्स *टूल* नोड हो सकते हैं जो किसी भी पायथन फ़ंक्शन या बाहरी API को कॉल करते हैं, इनपुट/आउटपुट का ऑटोमैटिक हैंडलिंग। |\\n| **रीयुज़ेबिलिटी और कंपोज़ेबिलिटी** | कोड मोनोलिथिक; सब‑वर्कफ़्लो को पुन: उपयोग करना कठिन। | सब‑ग्राफ नेस्ट, एक्सपोर्ट और फ़ंक्शन की तरह री‑यूज़ किए जा सकते हैं। |\\n| **ऑब्ज़र्वेबिलिटी और डिबगिंग** | यह ट्रैक करना मुश्किल कि कौन सा प्रॉम्प्ट कौन सा आउटपुट दिया। | रनटाइम स्थिति ट्रांज़िशन, नोड इनपुट/आउटपुट और एज निर्णय लॉग करता है, जिससे फ्लो को आसानी से निरीक्षण किया जा सकता है। |\\n\\n---  \\n\\n## प्रमुख घटक (उच्च‑स्तर)  \\n\\n1. **`State`** – एक परिवर्तनीय डिक्शनरी (या Pydantic मॉडल) जो निष्पादन के साथ यात्रा करती है।  \\n2. **`Node`** – कोई भी कॉलेबल जो वर्तमान स्थिति प्राप्त करता है और अपडेटेड स्थिति (या पार्टियल रिज़ल्ट) लौटाता है। सामान्य नोड प्रकार:  \\n   - `LLMNode` – LangChain प्रॉम्प्ट को LLM के साथ चलाता है।  \\n   - `ToolNode` – पायथन फ़ंक्शन या बाहरी सर्विस को कॉल करता है।  \\n   - `ConditionNode` – प्रेडिकेट का मूल्यांकन करता है और अगला एज तय करता है।  \\n   - `SubGraphNode` – किसी अन्य LangGraph ग्राफ को इनवोक करता है।  \\n3. **`Edge`** – एक फ़ंक्शन (या सरल मैपिंग) जो स्थिति के आधार पर अगले नोड की **की** लौटाता है।  \\n4. **`Graph`** – नोड्स + एजेज + एक *स्टार्ट* नोड का संग्रह।  \\n5. **`Executor`** – रनटाइम जो ग्राफ के माध्यम से स्टेप‑बाय‑स्टेप चलता है, स्थिति अपडेट करता है, लूप संभालता है और समाप्ति मानदंड का सम्मान करता है।  \\n\\n---  \\n\\n## न्यूनतम उदाहरण  \\n\\n```python\\nfrom langgraph.graph import Graph\\nfrom langgraph.nodes import LLMNode, ToolNode, ConditionNode\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.llms import OpenAI\\nimport math\\n\\n# 1️⃣ Define nodes\\nprompt = PromptTemplate.from_template(\\n    \"You are a math tutor. Solve: {question}\"\\n)\\nllm_node = LLMNode(OpenAI(), prompt, name=\"solve\")\\n\\ndef is_correct(state):\\n    # Very naive check – in real life you\\'d parse the answer or call a verifier tool\\n    return \"error\" not in state[\"answer\"].lower()\\n\\ncond_node = ConditionNode(is_correct, name=\"check\")\\n\\ndef calculator(state):\\n    # Simple tool that evaluates arithmetic expressions\\n    expr = state[\"question\"]\\n    state[\"answer\"] = str(eval(expr))\\n    return state\\n\\ntool_node = ToolNode(calculator, name=\"calc\")\\n\\n# 2️⃣ Build the graph\\ngraph = Graph(start_node=\"solve\")\\ngraph.add_node(llm_node)\\ngraph.add_node(tool_node)\\ngraph.add_node(cond_node)\\n\\n# Edges\\ngraph.add_edge(\"solve\", \"check\")          # after LLM, go to condition\\ngraph.add_edge(\"check\", \"calc\", condition=True)   # if not correct → calculator\\ngraph.add_edge(\"check\", \"end\", condition=False)  # if correct → finish\\n\\n# 3️⃣ Execute\\ninitial_state = {\"question\": \"12 * 7\"}\\nfinal_state = graph.run(initial_state)\\n\\nprint(final_state[\"answer\"])   # -> \"84\"\\n```\\n\\n*क्या होता है?*  \\n\\n1. **`solve`** LLM प्रॉम्प्ट चलाता है।  \\n2. **`check`** LLM के उत्तर की जाँच करता है।  \\n3. यदि उत्तर गलत दिखता है, तो एज **`calc`** की ओर ले जाता है, जो सीधे परिणाम गणना करता है।  \\n4. जब स्थिति में संतोषजनक उत्तर हो जाता है तो ग्राफ **`end`** पर समाप्त हो जाता है।  \\n\\n---  \\n\\n## सामान्य उपयोग‑केस  \\n\\n| डोमेन | उदाहरण कार्यप्रवाह (ग्राफ) |\\n|--------|----------------------------|\\n| **कस्टमर सपोर्ट** | `IntentClassifier → KnowledgeBaseLookup → ResponseGenerator → FeedbackLoop` |\\n| **रिसर्च असिस्टेंट** | `Plan → LiteratureSearch → Summarize → Synthesize → CiteSources` |\\n| **डेटा एनालिसिस** | `ParseUserQuery → ChooseTool (SQL / Pandas / Plot) → ExecuteTool → VerifyResult → Return` |\\n| **मल्टी‑एजेंट कोलैबोरेशन** | `Coordinator → AgentA (planning) → AgentB (execution) → AgentC (validation) → Merge` |\\n| **गेम AI / नैरेटिव** | `SceneGenerator → PlayerChoice → Branch → MemoryUpdate → NextScene` |\\n\\n---  \\n\\n## कैसे शुरू करें  \\n\\n```bash\\npip install langgraph\\n```\\n\\n1. **डॉक्यूमेंटेशन पढ़ें** – आधिकारिक साइट (https://langgraph.dev) पर *Getting Started* ट्यूटोरियल और `Graph`, `Node`, `Edge` के रेफ़रेंस उपलब्ध हैं।  \\n2. **बेस चुनें** – आप सीधे `Graph` से शुरू कर सकते हैं या हाई‑लेवल `StateGraph` हेल्पर का उपयोग कर सकते हैं जो आपके लिये `state` ऑब्जेक्ट बनाता है।  \\n3. **मौजूदा नोड्स का लाभ उठाएँ** – LangGraph में तैयार‑बनाए LLM नोड, टूल रैपर और कंडीशन नोड शामिल हैं, जो LangChain प्रॉम्प्ट टेम्पलेट और एजेंट्स के साथ संगत हैं।  \\n4. **इटरेट करें** – नए नोड जोड़ें, `graph.run(state)` से टेस्ट करें, और एक्सीक्यूशन लॉग देखें (`graph.visualize()` से Mermaid डायग्राम बन सकता है)।  \\n\\n---  \\n\\n## विज़ुअलाइज़ेशन  \\n\\nLangGraph ग्राफ को **Mermaid** या **GraphViz** में एक्सपोर्ट कर सकता है:  \\n\\n```python\\nprint(graph.to_mermaid())\\n# या\\ngraph.visualize(output_path=\"my_workflow.png\")\\n```  \\n\\nयह नॉन‑टेक्निकल स्टेकहोल्डर्स के साथ वर्कफ़्लो शेयर करना आसान बनाता है।  \\n\\n---  \\n\\n## संबंधित प्रोजेक्ट्स के साथ तुलना  \\n\\n| प्रोजेक्ट | मुख्य फोकस | ग्राफ समर्थन | स्थिति प्रबंधन | टूल एकीकरण |\\n|----------|------------|--------------|----------------|--------------|\\n| **LangChain** | प्रॉम्प्ट और एजेंट चेन | लीनियर/लूपेड चेन, स्पष्ट ग्राफ सिंटैक्स नहीं | `Chain` ऑब्जेक्ट्स के माध्यम से अप्रत्यक्ष | बिल्ट‑इन टूल रैपर्स |\\n| **AutoGPT** | सेल्फ‑प्रॉम्प्टिंग वाले ऑटोनॉमस एजेंट | इम्प्लिसिट “टास्क ग्राफ” सेल्फ‑रिफ्लेक्शन से | ग्लोबल मेमोरी स्टोर | टूल्स के लिए प्लगइन्स |\\n| **LlamaIndex** | डेटा‑सेंट्रिक रिट्रीवल‑ऑगमेंटेड जनरेशन | मुख्यतः रिट्रीवल पाइपलाइन | इंडेक्स‑ड्रिवेन स्टेट | डेटा सोर्स कनेक्टर्स |\\n| **LangGraph** | स्पष्ट **डायरेक्टेड ग्राफ** + **परिवर्तनीय स्टेट** | पूर्ण DAG/साइकल‑समर्थित ग्राफ | फ़र्स्ट‑क्लास `state` डिक्शनरी | नोड‑लेवल टूल कॉल, सब‑ग्राफ सपोर्ट |\\n\\nLangGraph को LangChain के साथ मिलाया जा सकता है (LLM नोड्स मूल रूप से LangChain चेन होते हैं) और LlamaIndex के साथ (रिट्रीवल नोड्स को टूल के रूप में जोड़ा जा सकता है)।  \\n\\n---  \\n\\n## TL;DR सारांश  \\n\\n- **LangGraph** = पायथन लाइब्रेरी जो **स्थिति‑सचेत ग्राफ‑आधारित LLM वर्कफ़्लो** को बनाना, चलाना और विज़ुअलाइज़ करना आसान बनाती है।  \\n- आप **नोड्स** (LLM कॉल, टूल कॉल, कंडीशन, सब‑ग्राफ) और **एजेज** (रूटिंग लॉजिक) को साझा **स्टेट** के साथ परिभाषित करते हैं।  \\n- यह **ब्रांचिंग, लूप, रीट्राई और कंपोज़ेबिलिटी** को बॉक्स से बाहर प्रदान करता है, जिससे जटिल मल्टी‑स्टेप LLM एप्लिकेशन लिखना, डिबग करना और मेंटेन करना सरल हो जाता है।  \\n- यह LangChain के ऊपर बना है, इसलिए मौजूदा प्रॉम्प्ट टेम्पलेट, LLM रैपर और टूल इंटीग्रेशन को पुनः उपयोग किया जा सकता है।  \\n\\nयदि आपको कई LLM कॉल, टूल इंटीग्रेशन और निर्णय बिंदुओं को एक संरचित, रखरखाव‑योग्य तरीके से ऑर्केस्ट्रेट करने की आवश्यकता है—विशेषकर जब फ्लो सिर्फ साधा लीनियर चेन नहीं है—तो LangGraph आपका मुख्य समाधान है।'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke({\"question\":\"What is LangGraph?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e8f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
